{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646e2d29",
   "metadata": {},
   "source": [
    "## Step - 1 Business Problem Understanding\n",
    "- **what is the relationship between each advertising channel (TV, Radio, Newspaper) and sales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d441062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df4fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a14fcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230100</td>\n",
       "      <td>37800</td>\n",
       "      <td>69200</td>\n",
       "      <td>22100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44500</td>\n",
       "      <td>39300</td>\n",
       "      <td>45100</td>\n",
       "      <td>10400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17200</td>\n",
       "      <td>45900</td>\n",
       "      <td>69300</td>\n",
       "      <td>9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151500</td>\n",
       "      <td>41300</td>\n",
       "      <td>58500</td>\n",
       "      <td>18500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180800</td>\n",
       "      <td>10800</td>\n",
       "      <td>58400</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TV  radio  newspaper  sales\n",
       "0  230100  37800      69200  22100\n",
       "1   44500  39300      45100  10400\n",
       "2   17200  45900      69300   9300\n",
       "3  151500  41300      58500  18500\n",
       "4  180800  10800      58400  12900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Advertising.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a22f99",
   "metadata": {},
   "source": [
    "## everything is same as we did in multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a301f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='sales')\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c764cbd",
   "metadata": {},
   "source": [
    "# Step -4 Modeling \n",
    "we will perform polynomial on both train data or test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18063f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best random state number: [99]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "Train = []\n",
    "Test = []\n",
    "CV = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    ypred_train = model.predict(X_train)\n",
    "    ypred_test = model.predict(X_test)\n",
    "\n",
    "    Train.append(model.score(X_train, y_train))\n",
    "    # print('Train R2:', r2_score(y_train, ypred_train))\n",
    "    Test.append(model.score(X_test, y_test))\n",
    "    # print('Test R2:', r2_score(y_test, ypred_test))\n",
    "\n",
    "    CV.append(cross_val_score(model, X_train, y_train, cv=5).mean())\n",
    "\n",
    "\n",
    "em = pd.DataFrame({'Train':Train, 'Test':Test, 'CV':CV})\n",
    "gm = em[(abs(em['Train']-em['Test']) <= 0.05) & (abs(em['Test']-em['CV']) <=0.05)]\n",
    "print('best random state number:', gm[gm['Test']==gm['Test'].max()].index.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c05c3",
   "metadata": {},
   "source": [
    "# <font color = aqua> Polynomial Regresion </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e273bd6",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "#### Choosing the best polynomial degree for given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f464d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "train_r2 = []\n",
    "test_r2 = []\n",
    "for i in range(1, 10):\n",
    "    # data preprocessing on train data\n",
    "    polynomial_converter = PolynomialFeatures(degree=i)\n",
    "    X_train_poly = pd.DataFrame(polynomial_converter.fit_transform(X_train))\n",
    "\n",
    "    # modelling on train data\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "    # prediction and evaluation on train data\n",
    "    ypred_train = model.predict(X_train_poly)\n",
    "    #print('Train R2:', i, model.score(X_train_poly, y_train))\n",
    "    train_r2.append(model.score(X_train_poly, y_train))\n",
    "\n",
    "    # transformation on test data\n",
    "    X_test_poly = pd.DataFrame(polynomial_converter.fit_transform(X_test))\n",
    "\n",
    "    # prediction and evaluation on test data\n",
    "    ypred_test = model.predict(X_test_poly)\n",
    "    #print('Test R2:', i, model.score(X_test_poly, y_test))\n",
    "    test_r2.append(model.score(X_test_poly, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d73659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8906288862925659,\n",
       " 0.9866683486567523,\n",
       " 0.9919477498440662,\n",
       " 0.9848303639971143,\n",
       " 0.9720950905621792,\n",
       " 0.9820606596510867,\n",
       " 0.9762257213001088,\n",
       " 0.8512235852604148,\n",
       " 0.9343409793417258]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd086ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9200846680148507,\n",
       " 0.9844905668728798,\n",
       " 0.9917498941105054,\n",
       " 0.9701214532745682,\n",
       " 0.9376875745936584,\n",
       " 0.8883176938749953,\n",
       " 0.5865878124892758,\n",
       " -0.6118354124362697,\n",
       " -2.904037216868102]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc15a6",
   "metadata": {},
   "source": [
    "##### between both train_r2 and test_r2, we can see index number 2 is having highest degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9930447",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65ff165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89dfc222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 5089.126947762041\n",
      "Coefficient: [ 0.00000000e+00  5.15901737e-02  1.54418707e-02  9.97897761e-03\n",
      " -1.08039513e-07  1.10610802e-06 -5.04606220e-08  1.19792603e-07\n",
      "  1.98539515e-07 -4.06233596e-08]\n",
      "Train RSME: 601.7940982044499\n",
      "Train R2: 0.9866683486567523\n",
      "Cross Validation Score: 0.8745389851558864\n",
      "Test RSME: 630.5318070675827\n",
      "Test R2: 0.9844905668728798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomial_converter = PolynomialFeatures(degree=2, include_bias=True)\n",
    "\n",
    "# data preprocessing on train data\n",
    "X_train_poly = pd.DataFrame(polynomial_converter.fit_transform(X_train))\n",
    "# data preprocessing on test data\n",
    "X_test_poly = pd.DataFrame(polynomial_converter.fit_transform(X_test))\n",
    "\n",
    "# modelling on train data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Coefficient:', model.coef_)\n",
    "\n",
    "# prediction\n",
    "ypred_train = model.predict(X_train_poly)\n",
    "ypred_test = model.predict(X_test_poly)\n",
    "\n",
    "# Evaluation \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('Train RSME:', np.sqrt(mean_squared_error(y_train, ypred_train)))\n",
    "print('Train R2:', r2_score(y_train, ypred_train))\n",
    "# Cross Validation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Cross Validation Score:', cross_val_score(model, X_train, y_train, cv=5).mean())\n",
    "\n",
    "# on test data, we are not required to do fit \n",
    "# (because B0 and B1 we find for the train daat only)\n",
    "\n",
    "# Evaluation on test data\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('Test RSME:', np.sqrt(mean_squared_error(y_test, ypred_test)))\n",
    "print('Test R2:', r2_score(y_test, ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c285ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y_train</td>     <th>  R-squared:         </th> <td>   0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   423.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 02 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>1.02e-74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:08:49</td>     <th>  Log-Likelihood:    </th> <td> -1419.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   160</td>      <th>  AIC:               </th> <td>   2847.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   156</td>      <th>  BIC:               </th> <td>   2859.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td> 2904.4859</td> <td>  368.721</td> <td>    7.877</td> <td> 0.000</td> <td> 2176.156</td> <td> 3632.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[0]</th> <td>    0.0455</td> <td>    0.002</td> <td>   28.499</td> <td> 0.000</td> <td>    0.042</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[1]</th> <td>    0.1882</td> <td>    0.010</td> <td>   18.941</td> <td> 0.000</td> <td>    0.169</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[2]</th> <td>    0.0008</td> <td>    0.007</td> <td>    0.114</td> <td> 0.909</td> <td>   -0.012</td> <td>    0.014</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>53.148</td> <th>  Durbin-Watson:     </th> <td>   1.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 134.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.386</td> <th>  Prob(JB):          </th> <td>5.54e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.539</td> <th>  Cond. No.          </th> <td>4.75e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.75e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &     y\\_train     & \\textbf{  R-squared:         } &     0.891   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.889   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     423.4   \\\\\n",
       "\\textbf{Date:}             & Fri, 02 Feb 2024 & \\textbf{  Prob (F-statistic):} &  1.02e-74   \\\\\n",
       "\\textbf{Time:}             &     01:08:49     & \\textbf{  Log-Likelihood:    } &   -1419.4   \\\\\n",
       "\\textbf{No. Observations:} &         160      & \\textbf{  AIC:               } &     2847.   \\\\\n",
       "\\textbf{Df Residuals:}     &         156      & \\textbf{  BIC:               } &     2859.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}   &    2904.4859  &      368.721     &     7.877  &         0.000        &     2176.156    &     3632.816     \\\\\n",
       "\\textbf{X\\_train[0]} &       0.0455  &        0.002     &    28.499  &         0.000        &        0.042    &        0.049     \\\\\n",
       "\\textbf{X\\_train[1]} &       0.1882  &        0.010     &    18.941  &         0.000        &        0.169    &        0.208     \\\\\n",
       "\\textbf{X\\_train[2]} &       0.0008  &        0.007     &     0.114  &         0.909        &       -0.012    &        0.014     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 53.148 & \\textbf{  Durbin-Watson:     } &    1.945  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  134.731  \\\\\n",
       "\\textbf{Skew:}          & -1.386 & \\textbf{  Prob(JB):          } & 5.54e-30  \\\\\n",
       "\\textbf{Kurtosis:}      &  6.539 & \\textbf{  Cond. No.          } & 4.75e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 4.75e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                y_train   R-squared:                       0.891\n",
       "Model:                            OLS   Adj. R-squared:                  0.889\n",
       "Method:                 Least Squares   F-statistic:                     423.4\n",
       "Date:                Fri, 02 Feb 2024   Prob (F-statistic):           1.02e-74\n",
       "Time:                        01:08:49   Log-Likelihood:                -1419.4\n",
       "No. Observations:                 160   AIC:                             2847.\n",
       "Df Residuals:                     156   BIC:                             2859.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2904.4859    368.721      7.877      0.000    2176.156    3632.816\n",
       "X_train[0]     0.0455      0.002     28.499      0.000       0.042       0.049\n",
       "X_train[1]     0.1882      0.010     18.941      0.000       0.169       0.208\n",
       "X_train[2]     0.0008      0.007      0.114      0.909      -0.012       0.014\n",
       "==============================================================================\n",
       "Omnibus:                       53.148   Durbin-Watson:                   1.945\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              134.731\n",
       "Skew:                          -1.386   Prob(JB):                     5.54e-30\n",
       "Kurtosis:                       6.539   Cond. No.                     4.75e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.75e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model1 = smf.ols('y_train ~ X_train', data=X_train).fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b5472",
   "metadata": {},
   "source": [
    "### Final model including TV and radio only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c45c6bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.drop(columns=['newspaper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93fff724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 5248.345923156818\n",
      "Coefficient: [ 0.00000000e+00  5.07736679e-02  2.19990110e-02 -1.08145346e-07\n",
      "  1.07163648e-06  2.73401133e-07]\n",
      "Train RSME: 620.4133821095758\n",
      "Train R2: 0.9858306342003403\n",
      "Cross Validation Score: 0.8803158236620214\n",
      "Test RSME: 597.3721467029545\n",
      "Test R2: 0.9860789541409101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "final_polynomial_converter = PolynomialFeatures(degree=2, include_bias=True)\n",
    "\n",
    "# data preprocessing on train data\n",
    "X_train_poly = pd.DataFrame(final_polynomial_converter.fit_transform(X_train))\n",
    "# data preprocessing on test data\n",
    "X_test_poly = pd.DataFrame(final_polynomial_converter.fit_transform(X_test))\n",
    "\n",
    "# modelling on train data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train_poly, y_train)\n",
    "print('Intercept:', model2.intercept_)\n",
    "print('Coefficient:', model2.coef_)\n",
    "\n",
    "# prediction\n",
    "ypred_train = model2.predict(X_train_poly)\n",
    "ypred_test = model2.predict(X_test_poly)\n",
    "\n",
    "# Evaluation \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('Train RSME:', np.sqrt(mean_squared_error(y_train, ypred_train)))\n",
    "print('Train R2:', r2_score(y_train, ypred_train))\n",
    "# Cross Validation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Cross Validation Score:', cross_val_score(model2, X_train, y_train, cv=5).mean())\n",
    "\n",
    "# on test data, we are not required to do fit \n",
    "# (because B0 and B1 we find for the train daat only)\n",
    "\n",
    "# Evaluation on test data\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('Test RSME:', np.sqrt(mean_squared_error(y_test, ypred_test)))\n",
    "print('Test R2:', r2_score(y_test, ypred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7cb78e",
   "metadata": {},
   "source": [
    "# Prediction on new data\n",
    "- Our next ad campaign will have a total spend of 149k on TV, 22k on Radio, and 12k on Newspaper Ads, how many units could we expect to sell as a result of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1b8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149000</td>\n",
       "      <td>22000</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TV  radio  newspaper\n",
       "0  149000  22000      12000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'TV':[149000], 'radio':[22000], 'newspaper':[12000]})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "823b8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df.drop(columns=['newspaper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63fb5896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 1.4900e+05, 2.2000e+04, 2.2201e+10, 3.2780e+09,\n",
       "        4.8400e+08]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformation\n",
    "transform_data = final_polynomial_converter.fit_transform(X)\n",
    "transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3455449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14541.81638092])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c08fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
